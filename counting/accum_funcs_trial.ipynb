{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook, load_workbook\n",
    "import pandas as pd\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows as df_to_row\n",
    "import numpy as np\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from szp_funcs import load_month, re_szp, re_szp_job, load_groups, print_df, months_year, custom_create_res, re_fot, re_fot_job, load_month_sum_by_job, accum_fot_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = months_year[:5]\n",
    "path_to_dir = 'C:\\\\Users\\\\PetukhovMD\\\\Documents\\\\code\\\\montly reports\\\\counting\\\\Accum + q stats\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_year_rus = ['янв', 'фев', 'мар', 'апр', 'май', 'июн', 'июл', 'авг', 'сен', 'окт', 'ноя', 'дек']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = custom_create_res(months, load_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_fot = custom_create_res(months, load_month_sum_by_job, on=['inn', 'snils', 'type', 'job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped, isp, aup = load_groups('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_grp_from_matcher(row, matcher, name_of_return='szp'):\n",
    "    if row['inn'] in matcher:\n",
    "        if row['snils'] in matcher[row['inn']]:\n",
    "            return row[name_of_return]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(months)):\n",
    "    t = i + 1\n",
    "    if t % 3 != 0:\n",
    "        continue\n",
    "    tm = months[:t]\n",
    "    res['szp_q_' + str(int(t/3))] = res.apply(lambda row: re_szp(row, tm), axis=1)\n",
    "    res['szp_teach_q_' + str(int(t/3))] = res.apply(lambda row: re_szp_job(row, tm, ['Учитель']), axis=1)\n",
    "    res['szp_ped_q_' + str(int(t/3))] = res.apply(lambda row: re_szp_job(row, tm, ped), axis=1)\n",
    "    res['fot_q_' + str(int(t/3))] = res.apply(lambda row: re_fot(row, tm), axis=1)\n",
    "    res['fot_aup_q_' + str(int(t/3))] = res.apply(lambda row: re_fot_job(row, tm, aup), axis=1)\n",
    "    df_all = res[res['szp_q_' + str(int(t/3))].isna() == False][['inn', 'snils', 'szp_q_' + str(int(t/3))]]\n",
    "    df_teach = res[res['szp_teach_q_' + str(int(t/3))].isna() == False][['inn', 'snils', 'szp_teach_q_' + str(int(t/3))]]\n",
    "    df_ped = res[res['szp_ped_q_' + str(int(t/3))].isna() == False][['inn', 'snils', 'szp_ped_q_' + str(int(t/3))]]\n",
    "    df_all = df_all.groupby('inn')\n",
    "    df_ped = df_ped.groupby('inn')\n",
    "    df_teach = df_teach.groupby('inn')\n",
    "    top10_all = {}\n",
    "    bot10_all = {}\n",
    "    top10_teach = {}\n",
    "    bot10_teach = {}\n",
    "    bot50_teach = {}\n",
    "    bot50_ped = {}\n",
    "    for group in df_all.groups:\n",
    "        cnt = df_all.get_group(group)['snils'].nunique()\n",
    "        top10_all[group] = df_all.get_group(group).sort_values(by='szp_q_' + str(int(t/3)), ascending=False, axis=0).head(ceil(cnt / 10))['snils'].to_list()\n",
    "        bot10_all[group] = df_all.get_group(group).sort_values(by='szp_q_' + str(int(t/3)), ascending=False, axis=0).tail(ceil(cnt / 10))['snils'].to_list()\n",
    "    for group in df_teach.groups:\n",
    "        cnt = df_teach.get_group(group)['snils'].nunique()\n",
    "        top10_teach[group] = df_teach.get_group(group).sort_values(by='szp_teach_q_' + str(int(t/3)), ascending=False, axis=0).head(ceil(cnt / 10))['snils'].to_list()\n",
    "        bot10_teach[group] = df_teach.get_group(group).sort_values(by='szp_teach_q_' + str(int(t/3)), ascending=False, axis=0).tail(ceil(cnt / 10))['snils'].to_list()\n",
    "        bot50_teach[group] = df_teach.get_group(group).sort_values(by='szp_teach_q_' + str(int(t/3)), ascending=False, axis=0).tail(ceil(cnt / 2))['snils'].to_list()\n",
    "    for group in df_ped.groups:\n",
    "        cnt = df_ped.get_group(group)['snils'].nunique()\n",
    "        bot50_ped[group] = df_ped.get_group(group).sort_values(by='szp_ped_q_' + str(int(t/3)), ascending=False, axis=0).tail(ceil(cnt / 2))['snils'].to_list()\n",
    "    res['top10_all_q_' + str(int(t/3))] = res.apply(lambda row: give_grp_from_matcher(row, top10_all, 'szp_q_' + str(int(t/3))), axis=1)\n",
    "    res['bot10_all_q_' + str(int(t/3))] = res.apply(lambda row: give_grp_from_matcher(row, bot10_all, 'szp_q_' + str(int(t/3))), axis=1)\n",
    "    res['top10_teach_q_' + str(int(t/3))] = res.apply(lambda row: give_grp_from_matcher(row, top10_teach, 'szp_teach_q_' + str(int(t/3))), axis=1)\n",
    "    res['bot10_teach_q_' + str(int(t/3))] = res.apply(lambda row: give_grp_from_matcher(row, bot10_teach, 'szp_teach_q_' + str(int(t/3))), axis=1)\n",
    "    res['bot50_teach_q_' + str(int(t/3))] = res.apply(lambda row: give_grp_from_matcher(row, bot50_teach, 'szp_teach_q_' + str(int(t/3))), axis=1)\n",
    "    res['bot50_ped_q_' + str(int(t/3))] = res.apply(lambda row: give_grp_from_matcher(row, bot50_ped, 'szp_ped_q_' + str(int(t/3))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['szp'] = res.apply(lambda row: re_szp(row, months), axis=1)\n",
    "res['szp_teach'] = res.apply(lambda row: re_szp_job(row, months, ['Учитель']), axis=1)\n",
    "res['szp_ped'] = res.apply(lambda row: re_szp_job(row, months, ped), axis=1)\n",
    "res['fot'] = res.apply(lambda row: re_fot(row, months), axis=1)\n",
    "res['fot_aup'] = res.apply(lambda row: re_fot_job(row, months, aup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = res[res.szp.isna() == False][['inn', 'snils', 'szp']]\n",
    "df_teach = res[res.szp_teach.isna() == False][['inn', 'snils', 'szp_teach']]\n",
    "df_ped = res[res.szp_ped.isna() == False][['inn', 'snils', 'szp_ped']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.groupby('inn')\n",
    "df_ped = df_ped.groupby('inn')\n",
    "df_teach = df_teach.groupby('inn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_all = {}\n",
    "bot10_all = {}\n",
    "top10_teach = {}\n",
    "bot10_teach = {}\n",
    "bot50_teach = {}\n",
    "bot50_ped = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in df_all.groups:\n",
    "    cnt = df_all.get_group(group)['snils'].nunique()\n",
    "    top10_all[group] = df_all.get_group(group).sort_values(by='szp', ascending=False, axis=0).head(ceil(cnt / 10))['snils'].to_list()\n",
    "    bot10_all[group] = df_all.get_group(group).sort_values(by='szp', ascending=False, axis=0).tail(ceil(cnt / 10))['snils'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in df_teach.groups:\n",
    "    cnt = df_teach.get_group(group)['snils'].nunique()\n",
    "    top10_teach[group] = df_teach.get_group(group).sort_values(by='szp_teach', ascending=False, axis=0).head(ceil(cnt / 10))['snils'].to_list()\n",
    "    bot10_teach[group] = df_teach.get_group(group).sort_values(by='szp_teach', ascending=False, axis=0).tail(ceil(cnt / 10))['snils'].to_list()\n",
    "    bot50_teach[group] = df_teach.get_group(group).sort_values(by='szp_teach', ascending=False, axis=0).tail(ceil(cnt / 2))['snils'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in df_ped.groups:\n",
    "    cnt = df_ped.get_group(group)['snils'].nunique()\n",
    "    bot50_ped[group] = df_ped.get_group(group).sort_values(by='szp_ped', ascending=False, axis=0).tail(ceil(cnt / 2))['snils'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['top10_all'] = res.apply(lambda row: give_grp_from_matcher(row, top10_all), axis=1)\n",
    "res['bot10_all'] = res.apply(lambda row: give_grp_from_matcher(row, bot10_all), axis=1)\n",
    "res['top10_teach'] = res.apply(lambda row: give_grp_from_matcher(row, top10_teach, 'szp_teach'), axis=1)\n",
    "res['bot10_teach'] = res.apply(lambda row: give_grp_from_matcher(row, bot10_teach, 'szp_teach'), axis=1)\n",
    "res['bot50_teach'] = res.apply(lambda row: give_grp_from_matcher(row, bot50_teach, 'szp_teach'), axis=1)\n",
    "res['bot50_ped'] = res.apply(lambda row: give_grp_from_matcher(row, bot50_ped, 'szp_ped'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_fot['fot'] = for_fot.apply(lambda row: re_fot(row, months), axis=1)\n",
    "for_fot['fot_aup'] = for_fot.apply(lambda row: accum_fot_job(row, months, aup), axis=1)\n",
    "for_fot['fot_isp'] = for_fot.apply(lambda row: accum_fot_job(row, months, isp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = res.groupby('inn')[['top10_all', 'top10_teach', 'bot50_teach', 'bot50_ped']].count().reset_index().rename(columns={'top10_all': 'dezil_cnt', 'top10_teach': 'dezil_teach_cnt', 'bot50_teach': 'teach_diff_cnt', 'bot50_ped': 'ped_diff_cnt'})\n",
    "means = res.groupby('inn')[['szp', 'szp_ped', 'szp_teach', 'top10_all', 'bot10_all', 'top10_teach', 'bot10_teach', 'bot50_teach', 'bot50_ped']].mean().reset_index()\n",
    "stats = pd.merge(means, cnts)\n",
    "stats['dezil'] = stats.top10_all / stats.bot10_all\n",
    "stats['dezil_teach'] = stats.top10_teach / stats.bot10_teach\n",
    "stats['teach_diff'] = stats.szp_teach / stats.bot50_teach\n",
    "print_df(pd.merge(stats, for_fot[for_fot.type != 'Внешнее совместительство'].groupby('inn')[['fot', 'fot_aup', 'fot_isp']].sum().reset_index()), path_to_dir + 'stats по ' + months[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_names = {'inn': (np.nan, 'ИНН'), 'snils': (np.nan, 'СНИЛС'), 'szp': (np.nan, 'СЗП'), 'szp_teach': (np.nan, 'СЗП учителей'),\n",
    "'szp_ped': (np.nan, 'СЗП педы'), 'fot': (np.nan, 'ФОТ'), 'fot_aup': (np.nan, 'ФОТ АУП'), 'top10_all': (np.nan, 'max 10% от всех работников'),\n",
    "'bot10_all': (np.nan, 'min 10% от всех работников'), 'top10_teach': (np.nan, 'max 10% учителей'), 'bot10_teach': (np.nan, 'min 10% учителей'),\n",
    "'bot50_teach': (np.nan, 'min 50% учителей'), 'bot50_ped': (np.nan, 'min 50% педагогов'), 'fot_isp': (np.nan, 'ФОТ НОУВП')}\n",
    "per_month_names = {'sum': (np.nan, 'Начисления'), 'job': (np.nan, 'Должность'), 'day': (np.nan, 'Отработанный месяц'),\n",
    "'type': (np.nan, 'Вид занятости'), 'stv': (np.nan, 'Ставка'), 'status': (np.nan, 'Статус на конец месяца'), 'status_pref': (np.nan, 'Статус на начало месяца'),\n",
    "'wday': (np.nan, 'Отработано дней'), 'nday': (np.nan, 'Всего рабочих дней в месяце')}\n",
    "monthly_names = {key: value for key, value in zip([key + '_' + month for key in per_month_names.keys() for month in months_year], [(month, value[1]) for value in per_month_names.values() for month in months_year_rus])}\n",
    "q_names = {key: value for key, value in zip([key + '_q_' + str(q) for key in static_names.keys() for q in range(1, 5)], [('кв_' + str(q), value[1]) for value in static_names.values() for q in range(1, 5)])}\n",
    "translate = static_names | per_month_names | monthly_names | q_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_with_trans(df_in, file, trans):\n",
    "    df = df_in.copy()\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.rename(columns=trans).columns.to_list())\n",
    "    row = [[] for i in df.columns.names]\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    for i in df.columns:\n",
    "        for j in range(len(row)):\n",
    "            row[j].append(i[j])\n",
    "    for i in row:\n",
    "        ws.append(i)\n",
    "    for i in df_to_row(df, header=False, index=False):\n",
    "        ws.append(i)\n",
    "    wb.save(file + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_with_trans(for_fot, path_to_dir + 'test_fot', translate)\n",
    "print_with_trans(res, path_to_dir + 'test', translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df(res, path_to_dir + 'accum по ' + months[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df(for_fot, path_to_dir + 'accum_fot по ' + months[-1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "074f563457da44d7ed57bdc37c43fd9dc993318bca70a60ea87af59e9047f938"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
