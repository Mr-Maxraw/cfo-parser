{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import Workbook\n",
    "from fuzzywuzzy import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from counting.szp_funcs import to_double, matcher, load_jobs, load_pay_types, months_year, print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_106 = load_jobs()\n",
    "pay_types = load_pay_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pre_job', 'job_106'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_106.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'name'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pay_types.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_up_jobs = job_106['pre_job'].unique().tolist()\n",
    "look_up_pay = pay_types['name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_names = []#['C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\2022_new\\\\Июнь 2022']\n",
    "#months = months_year[:5]\n",
    "path_to_dirt = 'C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\2022_new\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for file in os.listdir(path_to_dirt):\n",
    "    d = os.path.join(path_to_dirt, file)\n",
    "    if os.path.isdir(d):\n",
    "        dir_names.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\2022_new\\\\Апрель 2022',\n",
       " 'C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\2022_new\\\\Июнь 2022',\n",
       " 'C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\2022_new\\\\Май 2022',\n",
       " 'C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\2022_new\\\\Март 2022',\n",
       " 'C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\2022_new\\\\Февраль 2022',\n",
       " 'C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\2022_new\\\\Январь 2022']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['apr', 'jun', 'may', 'mar', 'feb', 'jan']\n",
    "post_path = 'C:\\\\Users\\\\PetukhovMD\\\\Desktop\\\\szp_2022\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nach_name = 'ДОНМ_Начисления работников_V2.xlsx'\n",
    "pay_name = 'ДОНМ_Начисления работников по категориямv2.xlsx'\n",
    "kadr_name = 'ДОНМ_Кадровые_паспортные данные v2.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_day(row):\n",
    "    if pd.isna(row['wday']) | pd.isna(row['nday']):\n",
    "        return 0\n",
    "    if row['wday'] >= row['nday']:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PetukhovMD\\AppData\\Local\\Temp\\ipykernel_18956\\3622959342.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_nach['stv'] = clean_nach.apply(lambda row: to_double(row, 'stv'), axis=1)\n",
      "C:\\Users\\PetukhovMD\\AppData\\Local\\Temp\\ipykernel_18956\\3622959342.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_nach['stv'] = clean_nach.apply(lambda row: to_double(row, 'stv'), axis=1)\n",
      "C:\\Users\\PetukhovMD\\AppData\\Local\\Temp\\ipykernel_18956\\3622959342.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_nach['stv'] = clean_nach.apply(lambda row: to_double(row, 'stv'), axis=1)\n",
      "C:\\Users\\PetukhovMD\\AppData\\Local\\Temp\\ipykernel_18956\\3622959342.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_nach['stv'] = clean_nach.apply(lambda row: to_double(row, 'stv'), axis=1)\n",
      "C:\\Users\\PetukhovMD\\AppData\\Local\\Temp\\ipykernel_18956\\3622959342.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_nach['stv'] = clean_nach.apply(lambda row: to_double(row, 'stv'), axis=1)\n",
      "C:\\Users\\PetukhovMD\\AppData\\Local\\Temp\\ipykernel_18956\\3622959342.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_nach['stv'] = clean_nach.apply(lambda row: to_double(row, 'stv'), axis=1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dir_names)):\n",
    "    nach = pd.read_excel(dir_names[i] + '\\\\' + nach_name)\n",
    "    clean_nach = nach.iloc[:, [2, 4, 8, 10, 11, 12, 13, 14, 16, 19, 21, 22, 23]]\n",
    "    clean_nach.columns = ['inn', 'snils', 'job_dirty', 'type', 'stv', 'status', 'sum_all', 'sum_curr', 'sum_prev', 'status_pref', 'wday', 'nday', 'spec']\n",
    "    clean_nach['stv'] = clean_nach.apply(lambda row: to_double(row, 'stv'), axis=1)\n",
    "    clean_nach = clean_nach.fillna({'sum_curr': 0, 'sum_prev': 0})\n",
    "    clean_nach['sum'] = clean_nach.sum_curr + clean_nach.sum_prev\n",
    "    clean_nach['day'] = clean_nach.apply(lambda row: give_day(row), axis=1)\n",
    "    cleaning_jobs = pd.DataFrame(clean_nach['job_dirty'].unique().tolist()).rename(columns={0: 'job_dirty'})\n",
    "    cleaning_jobs['pre_job'] = cleaning_jobs.apply(lambda row: matcher(row, look_up_jobs, 'job_dirty'), axis=1)\n",
    "    cleaning_jobs = pd.merge(cleaning_jobs, job_106, how='left').drop(columns=['pre_job']).rename(columns={'job_106': 'job'}).drop_duplicates('job_dirty')\n",
    "    clean_nach = pd.merge(clean_nach, cleaning_jobs, how='left').drop(columns=['job_dirty', 'sum_curr', 'sum_prev'])\n",
    "    print_df(clean_nach, post_path + months[i])\n",
    "    #print nach here month.xlsx\n",
    "    pay = pd.read_excel(dir_names[i] + '\\\\' + pay_name)\n",
    "    pay_clean = pay.iloc[:, [2, 3, 6, 10, 13, 14, 15, 16]]\n",
    "    pay_clean.columns = ['inn', 'snils', 'job_dirty', 'type', 'pre_name', 'nach_sum', 'kfo', 'nach_type']\n",
    "    pay_clean = pd.merge(pay_clean, cleaning_jobs, how='left').drop(columns=['job_dirty'])\n",
    "    print_df(pay_clean, post_path + months[i] + '_nach')\n",
    "    #print pay here month_nach.xlsx\n",
    "    kadr = pd.read_excel(dir_names[i] + '\\\\' + kadr_name)\n",
    "    kadr_clean = kadr.iloc[:, [2, 3, 7, 8, 9, 12]]\n",
    "    kadr_clean.columns = ['inn', 'snils', 'job_dirty', 'type', 'stv', 'status']\n",
    "    kadr_clean = pd.merge(kadr_clean, cleaning_jobs, how='left').drop(columns=['job_dirty'])\n",
    "    print_df(kadr_clean, post_path + months[i] + '_kadr')\n",
    "    #print kadr here month_kadr.xlsx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "074f563457da44d7ed57bdc37c43fd9dc993318bca70a60ea87af59e9047f938"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
